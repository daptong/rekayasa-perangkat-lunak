{
  "overall_metrics": {
    "pearson_r": 0.9036608990984328,
    "pearson_p_value": 2.645661076365493e-19,
    "spearman_r": 0.876658033654113,
    "spearman_p_value": 7.270297744538559e-17,
    "mae": 2.814738379241655,
    "rmse": 3.4769982834681366,
    "mean_bias": 0.9110910780329575,
    "agreement_within_5": 90.0,
    "agreement_within_10": 98.0,
    "num_samples": 50,
    "target_correlation": 0.76,
    "meets_target": "True"
  },
  "variation_metrics": [
    {
      "variation_type": "combination_errors",
      "num_samples": 5,
      "pearson_r": 0.3904490350378994,
      "p_value": 0.5158021160331002,
      "mae": 4.839380021869826,
      "rmse": 5.877609372522434,
      "mean_bias": 4.839380021869826,
      "mean_system_score": 74.50293210537595,
      "mean_human_score": 69.66355208350613
    },
    {
      "variation_type": "extra_classes",
      "num_samples": 5,
      "pearson_r": 0.9058608490544615,
      "p_value": 0.03417902551008916,
      "mae": 1.600521366350702,
      "rmse": 1.7867939580766528,
      "mean_bias": 1.600521366350702,
      "mean_system_score": 85.02723839672815,
      "mean_human_score": 83.42671703037745
    },
    {
      "variation_type": "minor_semantic",
      "num_samples": 10,
      "pearson_r": 0.5589523929812972,
      "p_value": 0.09301662953680187,
      "mae": 2.3340366073162855,
      "rmse": 2.714036032790439,
      "mean_bias": -0.9367572367566069,
      "mean_system_score": 89.84845322118898,
      "mean_human_score": 90.7852104579456
    },
    {
      "variation_type": "missing_attributes",
      "num_samples": 5,
      "pearson_r": 0.981098333585003,
      "p_value": 0.003110633357034924,
      "mae": 2.973118699630956,
      "rmse": 3.3690714080071,
      "mean_bias": 0.8752433921800759,
      "mean_system_score": 82.56703482611574,
      "mean_human_score": 81.69179143393565
    },
    {
      "variation_type": "missing_classes",
      "num_samples": 5,
      "pearson_r": 0.8466369731106278,
      "p_value": 0.07041465439872842,
      "mae": 2.9320939190239272,
      "rmse": 3.3015194455725196,
      "mean_bias": -1.564089000374119,
      "mean_system_score": 83.24603630473032,
      "mean_human_score": 84.81012530510444
    },
    {
      "variation_type": "missing_methods",
      "num_samples": 5,
      "pearson_r": 0.9281718686519511,
      "p_value": 0.02285811258356508,
      "mae": 2.9173848915202116,
      "rmse": 3.2936340224620313,
      "mean_bias": -0.27979623057927083,
      "mean_system_score": 75.37602131251661,
      "mean_human_score": 75.65581754309588
    },
    {
      "variation_type": "perfect_translation",
      "num_samples": 5,
      "pearson_r": NaN,
      "p_value": NaN,
      "mae": 2.218272349081096,
      "rmse": 2.9150011689409965,
      "mean_bias": 0.2501478829392312,
      "mean_system_score": 89.85730426994462,
      "mean_human_score": 89.6071563870054
    },
    {
      "variation_type": "spelling_errors",
      "num_samples": 5,
      "pearson_r": 0.497676971993594,
      "p_value": 0.39356570327697044,
      "mae": 1.3749351570672474,
      "rmse": 1.5936194777008474,
      "mean_bias": 0.6394136482163304,
      "mean_system_score": 90.57992622797458,
      "mean_human_score": 89.94051257975823
    },
    {
      "variation_type": "wrong_relationships",
      "num_samples": 5,
      "pearson_r": 0.5285392382978791,
      "p_value": 0.35984027891461745,
      "mae": 4.623604173240014,
      "rmse": 4.928357753141751,
      "mean_bias": 4.623604173240014,
      "mean_system_score": 83.87504923520628,
      "mean_human_score": 79.25144506196625
    }
  ],
  "confusion_matrix": {
    "Poor": {
      "Poor": 0,
      "Fair": 0,
      "Good": 0,
      "Excellent": 0
    },
    "Fair": {
      "Poor": 0,
      "Fair": 0,
      "Good": 1,
      "Excellent": 0
    },
    "Good": {
      "Poor": 0,
      "Fair": 3,
      "Good": 33,
      "Excellent": 10
    },
    "Excellent": {
      "Poor": 0,
      "Fair": 0,
      "Good": 1,
      "Excellent": 2
    }
  },
  "high_error_cases": [
    {
      "diagram_id": "student_049",
      "similarity_score": 80.64092164921045,
      "ged_value": 5.281434227277835,
      "max_possible_ged": 22.0,
      "normalized_ged": 0.2400651921489925,
      "semantic_score": 57.320366657915564,
      "structural_score": 85.71428571428572,
      "relationship_score": 50.0,
      "details": {
        "nodes_key": 7,
        "nodes_student": 6,
        "nodes_matched": 6,
        "nodes_missing": 1,
        "nodes_extra": 0,
        "edges_key": 8,
        "edges_student": 6,
        "edges_wrong_type": 2,
        "edges_missing": 2,
        "edges_extra": 0,
        "total_name_cost": 8.96272300183773,
        "total_attr_cost": 9.039507125814755,
        "total_method_cost": 6.532132426897683
      },
      "num_edit_operations": 23,
      "edit_operations_summary": {
        "node_substitutions": 21,
        "edge_wrong_types": 2,
        "total_operations": 23
      },
      "variation_type": "combination_errors",
      "expected_score_range": [
        40,
        60
      ],
      "modifications": [
        "Removed class: Faktur",
        "Removed attribute idKeranjang from KeranjangBelanja",
        "Removed attribute idPembayaran from Pembayaran",
        "Changed relationship rel_5 to generalization",
        "Changed relationship rel_1 to generalization"
      ],
      "human_score": 70.0,
      "nodes_key": 7,
      "nodes_student": 6,
      "nodes_matched": 6,
      "nodes_missing": 1,
      "nodes_extra": 0,
      "edges_key": 8,
      "edges_student": 6,
      "edges_wrong_type": 2,
      "system_category": "Good",
      "human_category": "Good",
      "error": 10.640921649210455,
      "abs_error": 10.640921649210455
    }
  ],
  "agreement_rates": {
    "within_3": 57.99999999999999,
    "within_5": 90.0,
    "within_7": 96.0,
    "within_10": 98.0,
    "within_15": 100.0
  },
  "statistical_significance": {
    "is_significant": "<CircularRef:bool_>",
    "significance_level": 0.05,
    "p_value": 2.645661076365493e-19
  }
}